{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc3f54e-59c1-418e-8eec-7e57a2780585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd67fcfa-45bf-4dc1-b017-3ea1cad42c26",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Fake.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the datasets\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m fake_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFake.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m true_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the first few rows of each dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Fake.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "fake_df = pd.read_csv(\"Fake.csv\")\n",
    "true_df = pd.read_csv(\"True.csv\")\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Fake News Sample:\")\n",
    "print(fake_df.head())\n",
    "\n",
    "print(\"\\nTrue News Sample:\")\n",
    "print(true_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efcf6a7-793c-42f2-9ace-9bf9716e7b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\OneDrive\\Desktop\\Fake_News_Detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # This will print the current working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3353052-3dbf-4a7c-9fa6-2e5e9e61886a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Extract Fake.csv.zip\n",
    "with zipfile.ZipFile(\"Fake.csv.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "# Extract True.csv.zip\n",
    "with zipfile.ZipFile(\"True.csv.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "print(\"Files extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d90cc65-ec96-4d4a-9b4a-07f81a207f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Sample:\n",
      "                                               title   \n",
      "0   Donald Trump Sends Out Embarrassing New Year’...  \\\n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text subject   \n",
      "0  Donald Trump just couldn t wish all Americans ...    News  \\\n",
      "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
      "2  On Friday, it was revealed that former Milwauk...    News   \n",
      "3  On Christmas day, Donald Trump announced that ...    News   \n",
      "4  Pope Francis used his annual Christmas Day mes...    News   \n",
      "\n",
      "                date  \n",
      "0  December 31, 2017  \n",
      "1  December 31, 2017  \n",
      "2  December 30, 2017  \n",
      "3  December 29, 2017  \n",
      "4  December 25, 2017  \n",
      "\n",
      "True News Sample:\n",
      "                                               title   \n",
      "0  As U.S. budget fight looms, Republicans flip t...  \\\n",
      "1  U.S. military to accept transgender recruits o...   \n",
      "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3  FBI Russia probe helped by Australian diplomat...   \n",
      "4  Trump wants Postal Service to charge 'much mor...   \n",
      "\n",
      "                                                text       subject   \n",
      "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews  \\\n",
      "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
      "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
      "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
      "\n",
      "                 date  \n",
      "0  December 31, 2017   \n",
      "1  December 29, 2017   \n",
      "2  December 31, 2017   \n",
      "3  December 30, 2017   \n",
      "4  December 29, 2017   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "fake_df = pd.read_csv(\"Fake.csv\")\n",
    "true_df = pd.read_csv(\"True.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Fake News Sample:\")\n",
    "print(fake_df.head())\n",
    "\n",
    "print(\"\\nTrue News Sample:\")\n",
    "print(true_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ee63a1-4baa-4e2b-908d-f54cd7477b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Sample:\n",
      "                                               title   \n",
      "0   Donald Trump Sends Out Embarrassing New Year’...  \\\n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text subject   \n",
      "0  Donald Trump just couldn t wish all Americans ...    News  \\\n",
      "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
      "2  On Friday, it was revealed that former Milwauk...    News   \n",
      "3  On Christmas day, Donald Trump announced that ...    News   \n",
      "4  Pope Francis used his annual Christmas Day mes...    News   \n",
      "\n",
      "                date  \n",
      "0  December 31, 2017  \n",
      "1  December 31, 2017  \n",
      "2  December 30, 2017  \n",
      "3  December 29, 2017  \n",
      "4  December 25, 2017   \n",
      "\n",
      "True News Sample:\n",
      "                                               title   \n",
      "0  As U.S. budget fight looms, Republicans flip t...  \\\n",
      "1  U.S. military to accept transgender recruits o...   \n",
      "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3  FBI Russia probe helped by Australian diplomat...   \n",
      "4  Trump wants Postal Service to charge 'much mor...   \n",
      "\n",
      "                                                text       subject   \n",
      "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews  \\\n",
      "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
      "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
      "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
      "\n",
      "                 date  \n",
      "0  December 31, 2017   \n",
      "1  December 29, 2017   \n",
      "2  December 31, 2017   \n",
      "3  December 30, 2017   \n",
      "4  December 29, 2017    \n",
      "\n",
      "Fake News Columns: Index(['title', 'text', 'subject', 'date'], dtype='object')\n",
      "True News Columns: Index(['title', 'text', 'subject', 'date'], dtype='object')\n",
      "\n",
      "Missing values in Fake News dataset:\n",
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in True News dataset:\n",
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the first few rows of each dataset\n",
    "print(\"Fake News Sample:\")\n",
    "print(fake_df.head(), \"\\n\")\n",
    "\n",
    "print(\"True News Sample:\")\n",
    "print(true_df.head(), \"\\n\")\n",
    "\n",
    "# Check column names\n",
    "print(\"Fake News Columns:\", fake_df.columns)\n",
    "print(\"True News Columns:\", true_df.columns)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in Fake News dataset:\")\n",
    "print(fake_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in True News dataset:\")\n",
    "print(true_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfbbe810-7324-4fdb-b7a8-045dc611cee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title   \n",
      "0  Ben Stein Calls Out 9th Circuit Court: Committ...  \\\n",
      "1  Trump drops Steve Bannon from National Securit...   \n",
      "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
      "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
      "4  Donald Trump heads for Scotland to reopen a go...   \n",
      "\n",
      "                                                text  label  \n",
      "0  21st Century Wire says Ben Stein, reputable pr...      1  \n",
      "1  WASHINGTON (Reuters) - U.S. President Donald T...      0  \n",
      "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...      0  \n",
      "3  On Monday, Donald Trump once again embarrassed...      1  \n",
      "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...      0  \n",
      "\n",
      "Dataset Shape: (44898, 3)\n"
     ]
    }
   ],
   "source": [
    "# Select only 'title' and 'text' columns and add a 'label' column\n",
    "fake_df['label'] = 1  # Fake news -> 1\n",
    "true_df['label'] = 0  # True news -> 0\n",
    "\n",
    "# Combine both datasets\n",
    "df = pd.concat([fake_df[['title', 'text', 'label']], true_df[['title', 'text', 'label']]], axis=0)\n",
    "\n",
    "# Shuffle the dataset to mix fake and true news\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display dataset structure\n",
    "print(df.head())\n",
    "print(\"\\nDataset Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b38f77-eea0-47f8-b525-7847ef5265ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title   \n",
      "0  Ben Stein Calls Out 9th Circuit Court: Committ...  \\\n",
      "1  Trump drops Steve Bannon from National Securit...   \n",
      "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
      "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
      "4  Donald Trump heads for Scotland to reopen a go...   \n",
      "\n",
      "                                                text  label  \n",
      "0  21st Century Wire says Ben Stein, reputable pr...      1  \n",
      "1  WASHINGTON (Reuters) - U.S. President Donald T...      0  \n",
      "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...      0  \n",
      "3  On Monday, Donald Trump once again embarrassed...      1  \n",
      "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...      0  \n",
      "\n",
      "Dataset Shape: (44898, 3)\n"
     ]
    }
   ],
   "source": [
    "# Select only 'title' and 'text' columns and add a 'label' column\n",
    "fake_df['label'] = 1  # Fake news -> 1\n",
    "true_df['label'] = 0  # True news -> 0\n",
    "\n",
    "# Combine both datasets\n",
    "df = pd.concat([fake_df[['title', 'text', 'label']], true_df[['title', 'text', 'label']]], axis=0)\n",
    "\n",
    "# Shuffle the dataset to mix fake and true news\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display dataset structure\n",
    "print(df.head())\n",
    "print(\"\\nDataset Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46188fd2-b741-4f40-b2a4-fc1d2735d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 35918\n",
      "Testing set size: 8980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Display dataset sizes\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac5a0d96-b4a3-4a08-a2d9-ca2fa7fb56e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Training Data Shape: (35918, 111193)\n",
      "TF-IDF Testing Data Shape: (8980, 111193)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "\n",
    "# Transform the text data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Display shape of transformed data\n",
    "print(\"TF-IDF Training Data Shape:\", X_train_tfidf.shape)\n",
    "print(\"TF-IDF Testing Data Shape:\", X_test_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e063f1-0998-4b0c-a595-08befa27b8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Model training completed\n",
    "print(\"Model training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30e4a924-0713-4c86-8a00-3cf82ccfef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.982739420935412\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4270\n",
      "           1       0.99      0.98      0.98      4710\n",
      "\n",
      "    accuracy                           0.98      8980\n",
      "   macro avg       0.98      0.98      0.98      8980\n",
      "weighted avg       0.98      0.98      0.98      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "# Display detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c17e28da-1f52-4d13-b246-76bdfd1b5313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    }
   ],
   "source": [
    "def predict_news(news_text):\n",
    "    # Transform the input text using the same TF-IDF vectorizer\n",
    "    news_tfidf = tfidf_vectorizer.transform([news_text])\n",
    "\n",
    "    # Predict using the trained model\n",
    "    prediction = model.predict(news_tfidf)\n",
    "\n",
    "    # Output result\n",
    "    return \"Fake News\" if prediction[0] == 1 else \"Real News\"\n",
    "\n",
    "# Example test\n",
    "sample_news = \"The government has announced a new economic policy to boost growth.\"\n",
    "print(\"Prediction:\", predict_news(sample_news))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73fa8e28-c5b7-43da-b2e4-216f1313f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(tfidf_vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, \"fake_news_model.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e38f38-f7a9-4c4c-8b29-4682b69fbd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    }
   ],
   "source": [
    "# Load the saved TF-IDF vectorizer and model\n",
    "loaded_vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "loaded_model = joblib.load(\"fake_news_model.pkl\")\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_news_from_saved_model(news_text):\n",
    "    news_tfidf = loaded_vectorizer.transform([news_text])\n",
    "    prediction = loaded_model.predict(news_tfidf)\n",
    "    return \"Fake News\" if prediction[0] == 1 else \"Real News\"\n",
    "\n",
    "# Example test\n",
    "sample_news = \"A new scientific breakthrough has been made in the fight against climate change.\"\n",
    "print(\"Prediction:\", predict_news_from_saved_model(sample_news))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92331964-649c-46b2-b4d8-55c9aea645e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Count: 23481\n",
      "Real News Count: 21417\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_fake = pd.read_csv(\"Fake.csv\")\n",
    "df_real = pd.read_csv(\"True.csv\")\n",
    "\n",
    "print(\"Fake News Count:\", len(df_fake))\n",
    "print(\"Real News Count:\", len(df_real))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
